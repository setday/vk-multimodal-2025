
# WikiArt Multimodal Retrieval — решение

Репозиторий содержит готовый прототип мультимодального поиска произведений искусства, выполненный в рамках домашнего задания. Система умеет:

- искать визуально похожие картины по изображению-запросу (Image -> Image),
- находить релевантные изображения по текстовому описанию/Caption (Caption -> Image),
- выполнять комбинированный поиск по свободному тексту, стилям, жанрам и zero-shot тегам, полученным от VLM (Omni -> Image),
- предоставлять интерактивное демо в Gradio, оборачивающее все три режима.

## Структура проекта

```
homeworks/hw-1/
├── artifacts/                # создаётся после сборки корпуса: эмбеддинги, индексы, датасеты
├── build_assets.py           # основной скрипт сборки (стриминг датасета -> эмбеддинги -> индексы)
├── demo.py                   # Gradio-интерфейс
├── notebooks/
│   └── wikiart_multimodal.ipynb   # воспроизводимый ноутбук с экспериментами
├── publish_captions.py       # выгрузка caption-датаcета на HuggingFace Datasets
├── requirements.txt
└── src/
	 ├── config.py             # конфигурации: пути, датасет, модели, индексы
	 ├── data.py               # стриминговая загрузка WikiArt
	 ├── embeddings.py         # обёртки над энкодерами (CLIP, BLIP)
	 ├── indexers.py           # обёртка над Annoy
	 ├── pipeline.py           # построение корпуса и индексов
	 ├── retrieval.py          # сервис для онлайн-запросов
	 └── utils.py
```

## Модели и мотивация

- **Image encoder:** `openai/clip-vit-base-patch32`. Выбор модели обусловлен несколькими факторами. Прежде всего, CLIP обеспечивает кросс-модальность, позволяя проецировать в одно векторное пространство как изображения, так и текстовые описания, что значительно упрощает реализацию мультимодального поиска. Несмотря на отсутствие специфической настройки на произведения искусства, модель демонстрирует высокую эффективность в улавливании художественных стилей, композиционных элементов и тематического содержания, что хорошо заметно при поиске по схожим картинкам. С технической стороны, эта модель из библиотеки Transformers предоставляет L2-нормированные эмбеддинги размерности 512, что упрощает применение косинусных метрик сходства без необходимости дополнительной нормализации.
- **Captioning:** `Salesforce/blip-image-captioning-large`. Модель BLIP была выбрана для генерации описаний к изображениям благодаря её способности создавать короткие, но в то же время общие описания к визуальному контенту, что позволяет более эффективно осуществлять индексацию. 

## Индексы

На Windows использовать FAISS затруднительно, поэтому вместо него выбран **Annoy** (approximate nearest neighbours на основе деревьев). Для каждого режима строится свой индекс:

- `image.ann` — визуальные эмбеддинги картинок,
- `caption.ann` — текстовые эмбеддинги сгенерированных описаний,
- `omni.ann` — вектор похожести на множество zero-shot тегов.

## Потоковая загрузка WikiArt

`src/data.py` использует `load_dataset(..., streaming=True)` и `shuffle(seed=42, buffer_size=2048)`, что гарантирует детерминированную последовательность образцов без локального скачивания полного датасета. Значение `sample_size` по умолчанию — `5000`.

## Сборка корпуса

1. Установите зависимости:

	```powershell
	cd homeworks/hw-1
	python -m venv .venv
	.venv\Scripts\Activate.ps1
	pip install -r requirements.txt
	```

2. Запустите пайплайн сборки (~20 минут в зависимости от GPU/CPU):

	```powershell
	python build_assets.py
	```

	Скрипт:
	- считывает 5000 изображений из стрима WikiArt,
	- сохраняет сами изображения и метаданные в `artifacts/`,
	- считает эмбеддинги CLIP и captions BLIP,
	- формирует zero-shot признаки,
	- строит Annoy-индексы и сериализует всё на диск.

## Ноутбук `wikiart_multimodal.ipynb`

В ноутбуке отражены ключевые шаги:

1. Инициализация окружения и фиксирование сида.
2. Просмотр первых примеров из стримингового датасета.
3. Полный запуск `build_corpus(sample_size=5000)`.
4. Инициализация `RetrievalService` и проверка количества элементов.
5. Демонстрация трёх режимов поиска на случайно выбранном образце.
6. Запуск Gradio-дема из ноутбука.

Все ячейки выполнены последовательно; для полного воспроизведения достаточно прогнать ноутбук сверху вниз после установки зависимостей.

## Gradio демо

После сборки корпуса запустите:

```powershell
python demo.py
```

Откроется локальный веб-интерфейс с тремя вкладками, позволяющими проверять все режимы поиска. Вкладки возвращают таблицу с путём к файлу, названием, автором, стилем, жанром, caption и дистанцией.

## Публикация датасета caption'ов на HuggingFace

После сборки корпуса выполните:

	```powershell
	python publish_captions.py <username>/wikiart-captions --api_token <your_hf_api_token>
	```

	Скрипт создаст датасет с одним сплитом `train`, содержащим поля `id`, `caption` и `image_row` (всегда `null`; имеет значения байтов изображения).
